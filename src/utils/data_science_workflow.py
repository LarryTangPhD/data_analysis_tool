"""
æ•°æ®ç§‘å­¦å·¥ä½œæµç®¡ç†æ¨¡å—
æä¾›æ ‡å‡†åŒ–çš„æ•°æ®åˆ†ææµç¨‹å’Œæœ€ä½³å®è·µ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import streamlit as st
from dataclasses import dataclass
from enum import Enum
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WorkflowStage(Enum):
    """å·¥ä½œæµé˜¶æ®µæšä¸¾"""
    DATA_LOADING = "æ•°æ®åŠ è½½"
    DATA_EXPLORATION = "æ•°æ®æ¢ç´¢"
    DATA_CLEANING = "æ•°æ®æ¸…æ´—"
    FEATURE_ENGINEERING = "ç‰¹å¾å·¥ç¨‹"
    MODELING = "å»ºæ¨¡åˆ†æ"
    EVALUATION = "æ¨¡å‹è¯„ä¼°"
    DEPLOYMENT = "ç»“æœéƒ¨ç½²"

@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥éª¤æ•°æ®ç±»"""
    stage: WorkflowStage
    name: str
    description: str
    completed: bool = False
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    metrics: Dict[str, Any] = None
    artifacts: List[str] = None

class DataScienceWorkflow:
    """æ•°æ®ç§‘å­¦å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self):
        self.steps: List[WorkflowStep] = []
        self.current_step_index = 0
        self.workflow_start_time = datetime.now()
        self.metadata = {}
        
        # åˆå§‹åŒ–æ ‡å‡†å·¥ä½œæµ
        self._initialize_standard_workflow()
    
    def _initialize_standard_workflow(self):
        """åˆå§‹åŒ–æ ‡å‡†æ•°æ®ç§‘å­¦å·¥ä½œæµ"""
        standard_steps = [
            WorkflowStep(
                stage=WorkflowStage.DATA_LOADING,
                name="æ•°æ®åŠ è½½ä¸éªŒè¯",
                description="åŠ è½½æ•°æ®æ–‡ä»¶ï¼ŒéªŒè¯æ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§"
            ),
            WorkflowStep(
                stage=WorkflowStage.DATA_EXPLORATION,
                name="æ¢ç´¢æ€§æ•°æ®åˆ†æ",
                description="åˆ†ææ•°æ®åˆ†å¸ƒã€ç›¸å…³æ€§ã€ç¼ºå¤±å€¼ç­‰åŸºæœ¬ç‰¹å¾"
            ),
            WorkflowStep(
                stage=WorkflowStage.DATA_CLEANING,
                name="æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†",
                description="å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€é‡å¤å€¼ï¼Œæ ‡å‡†åŒ–æ•°æ®æ ¼å¼"
            ),
            WorkflowStep(
                stage=WorkflowStage.FEATURE_ENGINEERING,
                name="ç‰¹å¾å·¥ç¨‹",
                description="ç‰¹å¾é€‰æ‹©ã€è½¬æ¢ã€åˆ›å»ºæ–°ç‰¹å¾"
            ),
            WorkflowStep(
                stage=WorkflowStage.MODELING,
                name="æ¨¡å‹æ„å»º",
                description="é€‰æ‹©åˆé€‚çš„ç®—æ³•ï¼Œè®­ç»ƒå’Œè°ƒä¼˜æ¨¡å‹"
            ),
            WorkflowStep(
                stage=WorkflowStage.EVALUATION,
                name="æ¨¡å‹è¯„ä¼°",
                description="ä½¿ç”¨å¤šç§æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ€§èƒ½"
            ),
            WorkflowStep(
                stage=WorkflowStage.DEPLOYMENT,
                name="ç»“æœéƒ¨ç½²",
                description="ç”ŸæˆæŠ¥å‘Šï¼Œéƒ¨ç½²æ¨¡å‹æˆ–ç»“æœ"
            )
        ]
        
        self.steps = standard_steps
    
    def start_step(self, step_name: str) -> bool:
        """å¼€å§‹æ‰§è¡Œå·¥ä½œæµæ­¥éª¤"""
        for i, step in enumerate(self.steps):
            if step.name == step_name:
                step.start_time = datetime.now()
                step.completed = False
                self.current_step_index = i
                logger.info(f"å¼€å§‹æ‰§è¡Œæ­¥éª¤: {step_name}")
                return True
        return False
    
    def complete_step(self, step_name: str, metrics: Dict[str, Any] = None, artifacts: List[str] = None) -> bool:
        """å®Œæˆå·¥ä½œæµæ­¥éª¤"""
        for step in self.steps:
            if step.name == step_name:
                step.end_time = datetime.now()
                step.completed = True
                step.metrics = metrics or {}
                step.artifacts = artifacts or []
                logger.info(f"å®Œæˆæ­¥éª¤: {step_name}")
                return True
        return False
    
    def get_current_step(self) -> Optional[WorkflowStep]:
        """è·å–å½“å‰æ­¥éª¤"""
        if 0 <= self.current_step_index < len(self.steps):
            return self.steps[self.current_step_index]
        return None
    
    def get_progress(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµè¿›åº¦"""
        completed_steps = sum(1 for step in self.steps if step.completed)
        total_steps = len(self.steps)
        progress_percentage = (completed_steps / total_steps) * 100
        
        return {
            "completed_steps": completed_steps,
            "total_steps": total_steps,
            "progress_percentage": progress_percentage,
            "current_step": self.get_current_step(),
            "workflow_duration": datetime.now() - self.workflow_start_time
        }
    
    def get_workflow_summary(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµæ€»ç»“"""
        completed_steps = [step for step in self.steps if step.completed]
        pending_steps = [step for step in self.steps if not step.completed]
        
        return {
            "workflow_name": "æ ‡å‡†æ•°æ®ç§‘å­¦å·¥ä½œæµ",
            "start_time": self.workflow_start_time,
            "current_time": datetime.now(),
            "completed_steps": len(completed_steps),
            "pending_steps": len(pending_steps),
            "total_steps": len(self.steps),
            "completion_rate": (len(completed_steps) / len(self.steps)) * 100,
            "completed_step_details": [
                {
                    "name": step.name,
                    "duration": step.end_time - step.start_time if step.end_time and step.start_time else None,
                    "metrics": step.metrics
                }
                for step in completed_steps
            ]
        }

def render_workflow_dashboard(workflow: DataScienceWorkflow):
    """æ¸²æŸ“å·¥ä½œæµä»ªè¡¨æ¿"""
    st.subheader("ğŸ“Š æ•°æ®ç§‘å­¦å·¥ä½œæµä»ªè¡¨æ¿")
    
    # è·å–è¿›åº¦ä¿¡æ¯
    progress = workflow.get_progress()
    
    # è¿›åº¦æ¡
    st.progress(progress["progress_percentage"] / 100)
    st.write(f"**è¿›åº¦**: {progress['completed_steps']}/{progress['total_steps']} æ­¥éª¤å®Œæˆ ({progress['progress_percentage']:.1f}%)")
    
    # å½“å‰æ­¥éª¤
    current_step = progress["current_step"]
    if current_step:
        st.info(f"**å½“å‰æ­¥éª¤**: {current_step.name} - {current_step.description}")
    
    # å·¥ä½œæµæ­¥éª¤åˆ—è¡¨
    st.subheader("ğŸ“‹ å·¥ä½œæµæ­¥éª¤")
    
    for i, step in enumerate(workflow.steps):
        col1, col2, col3 = st.columns([1, 3, 1])
        
        with col1:
            if step.completed:
                st.success("âœ…")
            elif i == workflow.current_step_index:
                st.info("ğŸ”„")
            else:
                st.write("â³")
        
        with col2:
            st.write(f"**{step.name}**")
            st.write(f"*{step.description}*")
            
            if step.completed and step.metrics:
                with st.expander("æŸ¥çœ‹æŒ‡æ ‡"):
                    for metric_name, metric_value in step.metrics.items():
                        st.write(f"â€¢ {metric_name}: {metric_value}")
        
        with col3:
            if step.completed and step.start_time and step.end_time:
                duration = step.end_time - step.start_time
                st.write(f"â±ï¸ {duration.total_seconds():.1f}s")

def create_custom_workflow(workflow_type: str) -> DataScienceWorkflow:
    """åˆ›å»ºè‡ªå®šä¹‰å·¥ä½œæµ"""
    workflow = DataScienceWorkflow()
    
    if workflow_type == "å¿«é€Ÿåˆ†æ":
        # ç®€åŒ–çš„å¿«é€Ÿåˆ†æå·¥ä½œæµ
        quick_steps = [
            WorkflowStep(
                stage=WorkflowStage.DATA_LOADING,
                name="æ•°æ®åŠ è½½",
                description="å¿«é€ŸåŠ è½½å’ŒéªŒè¯æ•°æ®"
            ),
            WorkflowStep(
                stage=WorkflowStage.DATA_EXPLORATION,
                name="å¿«é€Ÿæ¢ç´¢",
                description="åŸºç¡€æ•°æ®æ¦‚è§ˆå’Œå¯è§†åŒ–"
            ),
            WorkflowStep(
                stage=WorkflowStage.DEPLOYMENT,
                name="ç”ŸæˆæŠ¥å‘Š",
                description="å¿«é€Ÿç”Ÿæˆåˆ†ææŠ¥å‘Š"
            )
        ]
        workflow.steps = quick_steps
    
    elif workflow_type == "æ·±åº¦åˆ†æ":
        # æ·±åº¦åˆ†æå·¥ä½œæµï¼ŒåŒ…å«æ›´å¤šæ­¥éª¤
        deep_steps = workflow.steps + [
            WorkflowStep(
                stage=WorkflowStage.FEATURE_ENGINEERING,
                name="é«˜çº§ç‰¹å¾å·¥ç¨‹",
                description="å¤æ‚çš„ç‰¹å¾è½¬æ¢å’Œé€‰æ‹©"
            ),
            WorkflowStep(
                stage=WorkflowStage.MODELING,
                name="å¤šæ¨¡å‹æ¯”è¾ƒ",
                description="è®­ç»ƒå’Œæ¯”è¾ƒå¤šä¸ªæ¨¡å‹"
            )
        ]
        workflow.steps = deep_steps
    
    return workflow

def validate_data_for_workflow(data: pd.DataFrame) -> Dict[str, Any]:
    """éªŒè¯æ•°æ®æ˜¯å¦é€‚åˆå·¥ä½œæµåˆ†æ"""
    validation_results = {
        "is_valid": True,
        "warnings": [],
        "errors": [],
        "recommendations": []
    }
    
    # æ£€æŸ¥æ•°æ®å¤§å°
    if len(data) < 10:
        validation_results["warnings"].append("æ•°æ®é‡è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æå¯é æ€§")
    
    if len(data.columns) < 2:
        validation_results["errors"].append("æ•°æ®åˆ—æ•°è¿‡å°‘ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆåˆ†æ")
        validation_results["is_valid"] = False
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_ratio = data.isnull().sum().sum() / (len(data) * len(data.columns))
    if missing_ratio > 0.5:
        validation_results["warnings"].append(f"ç¼ºå¤±å€¼æ¯”ä¾‹è¾ƒé«˜ ({missing_ratio:.1%})ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) == 0:
        validation_results["warnings"].append("æ²¡æœ‰æ•°å€¼å‹åˆ—ï¼ŒæŸäº›åˆ†æåŠŸèƒ½å¯èƒ½å—é™")
    
    # æä¾›å»ºè®®
    if len(data) > 1000:
        validation_results["recommendations"].append("æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨é‡‡æ ·è¿›è¡Œå¿«é€Ÿæ¢ç´¢")
    
    if len(numeric_cols) > 10:
        validation_results["recommendations"].append("ç‰¹å¾è¾ƒå¤šï¼Œå»ºè®®è¿›è¡Œç‰¹å¾é€‰æ‹©")
    
    return validation_results

def generate_workflow_report(workflow: DataScienceWorkflow, data: pd.DataFrame) -> str:
    """ç”Ÿæˆå·¥ä½œæµæŠ¥å‘Š"""
    summary = workflow.get_workflow_summary()
    
    report = f"""
# æ•°æ®ç§‘å­¦å·¥ä½œæµæŠ¥å‘Š

## å·¥ä½œæµæ¦‚è§ˆ
- **å·¥ä½œæµåç§°**: {summary['workflow_name']}
- **å¼€å§‹æ—¶é—´**: {summary['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
- **å®Œæˆæ—¶é—´**: {summary['current_time'].strftime('%Y-%m-%d %H:%M:%S')}
- **å®Œæˆç‡**: {summary['completion_rate']:.1f}%

## æ•°æ®é›†ä¿¡æ¯
- **æ•°æ®è§„æ¨¡**: {len(data)} è¡Œ Ã— {len(data.columns)} åˆ—
- **æ•°æ®ç±»å‹**: {', '.join([f'{dtype}({count})' for dtype, count in data.dtypes.value_counts().items()])}
- **ç¼ºå¤±å€¼**: {data.isnull().sum().sum()} ä¸ª

## å®Œæˆæ­¥éª¤è¯¦æƒ…
"""
    
    for step_detail in summary['completed_step_details']:
        report += f"""
### {step_detail['name']}
- **æ‰§è¡Œæ—¶é•¿**: {step_detail['duration'].total_seconds():.1f} ç§’
"""
        if step_detail['metrics']:
            report += "- **å…³é”®æŒ‡æ ‡**:\n"
            for metric_name, metric_value in step_detail['metrics'].items():
                report += f"  - {metric_name}: {metric_value}\n"
    
    return report
