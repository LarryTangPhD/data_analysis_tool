"""
æ•´æ´æ•°æ®è½¬æ¢å™¨
ä¸“é—¨ç”¨äºå°†å¤æ‚JSONæ•°æ®è½¬æ¢ä¸ºç¬¦åˆTidy DataåŸåˆ™çš„æ•´æ´æ ¼å¼
"""

import pandas as pd
import json
import streamlit as st
from typing import Dict, Any, List, Optional, Union
import io
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class TidyDataConverter:
    """æ•´æ´æ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self):
        self.supported_input_formats = ['json', 'csv', 'xlsx', 'xls', 'parquet', 'txt']
        self.supported_output_formats = ['csv', 'xlsx', 'parquet', 'json']
    
    def convert_to_tidy_data(self, 
                            json_data: Union[str, List, Dict], 
                            separator: str = ".", 
                            fill_na: str = "",
                            max_preview_rows: int = 10,
                            encoding: str = "utf-8-sig") -> Dict[str, Any]:
        """
        å°†JSONæ•°æ®è½¬æ¢ä¸ºçœŸæ­£çš„æ•´æ´æ•°æ®
        
        Args:
            json_data: JSONæ•°æ®ï¼ˆå­—ç¬¦ä¸²ã€åˆ—è¡¨æˆ–å­—å…¸ï¼‰
            separator: åµŒå¥—å­—æ®µåˆ†éš”ç¬¦
            fill_na: ç¼ºå¤±å€¼å¡«å……
            max_preview_rows: é¢„è§ˆè¡Œæ•°
            encoding: è¾“å‡ºç¼–ç 
            
        Returns:
            åŒ…å«è½¬æ¢ç»“æœå’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            # è§£æJSONæ•°æ®
            if isinstance(json_data, str):
                data = json.loads(json_data)
            else:
                data = json_data
            
            # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(data, dict):
                list_candidates = [v for v in data.values() if isinstance(v, list)]
                if len(list_candidates) == 1:
                    data = list_candidates[0]
                    extracted_field = [k for k, v in data.items() if v == data][0]
                    info_message = f"æ£€æµ‹åˆ°åµŒå¥—ç»“æ„ï¼Œå·²æå–å­—æ®µ `{extracted_field}` è¿›è¡Œè½¬æ¢ã€‚"
                else:
                    info_message = "JSONé¡¶å±‚ä¸ºå¯¹è±¡ä½†æœªæ‰¾åˆ°å¯è½¬æ¢çš„æ•°ç»„å­—æ®µã€‚å°è¯•ç›´æ¥å±•å¼€ã€‚"
                    data = [data]
            elif not isinstance(data, list):
                raise ValueError("JSONæ ¹èŠ‚ç‚¹å¿…é¡»æ˜¯æ•°ç»„æˆ–å¯è½¬æ¢çš„å¯¹è±¡ã€‚")
            else:
                info_message = "JSONæ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¼€å§‹è½¬æ¢ã€‚"
            
            # ç¬¬ä¸€æ­¥ï¼šé€’å½’å±•å¼€æ‰€æœ‰åµŒå¥—åˆ—è¡¨
            expanded_data = []
            for item in data:
                expanded_items = self._recursive_expand_lists(item)
                expanded_data.extend(expanded_items)
            
            # ç¬¬äºŒæ­¥ï¼šå®Œå…¨æ‰å¹³åŒ–æ‰€æœ‰åµŒå¥—å­—å…¸
            flattened_data = []
            for item in expanded_data:
                flattened_item = self._flatten_all_dicts(item, separator)
                flattened_data.append(flattened_item)
            
            # ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºDataFrame
            df = pd.DataFrame(flattened_data)
            
            # ç¬¬å››æ­¥ï¼šå¡«å……ç¼ºå¤±å€¼
            df = df.fillna(fill_na)
            
            # ç¬¬äº”æ­¥ï¼šé‡ç½®ç´¢å¼•
            df = df.reset_index(drop=True)
            
            # ç”ŸæˆCSVæ•°æ®
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False, encoding=encoding)
            csv_data = csv_buffer.getvalue()
            
            # åˆ†æè½¬æ¢æ•ˆæœ
            analysis = self._analyze_tidy_data_quality(df)
            
            return {
                'success': True,
                'dataframe': df,
                'csv_data': csv_data,
                'info_message': info_message,
                'explode_message': f"å·²å®Œå…¨å±•å¼€æ‰€æœ‰åˆ—è¡¨å­—æ®µï¼Œå…±ç”Ÿæˆ {len(df)} è¡Œæ•´æ´æ•°æ®ã€‚",
                'preview_data': df.head(max_preview_rows),
                'shape': df.shape,
                'columns': df.columns.tolist(),
                'dtypes': df.dtypes.to_dict(),
                'tidy_analysis': analysis
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'dataframe': None,
                'csv_data': None
            }
    
    def _recursive_expand_lists(self, item):
        """é€’å½’å±•å¼€æ‰€æœ‰åµŒå¥—åˆ—è¡¨å­—æ®µ"""
        if not isinstance(item, dict):
            return [item]
        
        # ä½¿ç”¨pandasçš„json_normalizeæ¥å¤„ç†åµŒå¥—ç»“æ„
        import pandas as pd
        
        # å°†å•ä¸ªå­—å…¸è½¬æ¢ä¸ºDataFrame
        df = pd.json_normalize(item, sep='.')
        
        # æ‰¾å‡ºåŒ…å«åˆ—è¡¨çš„åˆ—
        list_columns = []
        for col in df.columns:
            if df[col].apply(lambda x: isinstance(x, list)).any():
                list_columns.append(col)
        
        if not list_columns:
            return [item]
        
        # å±•å¼€ç¬¬ä¸€ä¸ªåˆ—è¡¨åˆ—
        first_list_col = list_columns[0]
        expanded_df = df.explode(first_list_col)
        
        # å¦‚æœå±•å¼€çš„åˆ—åŒ…å«å­—å…¸ï¼Œéœ€è¦è¿›ä¸€æ­¥æ‰å¹³åŒ–
        if expanded_df[first_list_col].apply(lambda x: isinstance(x, dict)).any():
            # å°†å±•å¼€çš„DataFrameè½¬æ¢å›å­—å…¸åˆ—è¡¨
            expanded_records = []
            for _, row in expanded_df.iterrows():
                record = row.to_dict()
                # å¤„ç†å±•å¼€çš„å­—å…¸
                if isinstance(record[first_list_col], dict):
                    # å°†å­—å…¸çš„é”®å€¼å¯¹æ·»åŠ åˆ°è®°å½•ä¸­
                    for key, value in record[first_list_col].items():
                        record[f"{first_list_col}.{key}"] = value
                    # åˆ é™¤åŸå§‹çš„åˆ—è¡¨åˆ—
                    del record[first_list_col]
                expanded_records.append(record)
            return expanded_records
        else:
            # ç®€å•åˆ—è¡¨ï¼Œç›´æ¥è½¬æ¢å›å­—å…¸åˆ—è¡¨
            return expanded_df.to_dict('records')
    
    def _process_nested_lists(self, obj):
        """é€’å½’å¤„ç†åµŒå¥—å­—å…¸ä¸­çš„åˆ—è¡¨å­—æ®µ"""
        if not isinstance(obj, dict):
            return obj
        
        processed = {}
        for key, value in obj.items():
            if isinstance(value, dict):
                # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                processed[key] = self._process_nested_lists(value)
            elif isinstance(value, list):
                # å¤„ç†åˆ—è¡¨ä¸­çš„å­—å…¸å…ƒç´ 
                if len(value) > 0 and isinstance(value[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œé€’å½’å¤„ç†æ¯ä¸ªå­—å…¸
                    processed_list = []
                    for item in value:
                        processed_item = self._process_nested_lists(item)
                        processed_list.append(processed_item)
                    processed[key] = processed_list
                else:
                    processed[key] = value
            else:
                processed[key] = value
        
        return processed
    
    def _flatten_all_dicts(self, obj, separator="."):
        """é€’å½’æ‰å¹³åŒ–æ‰€æœ‰å­—å…¸ç»“æ„"""
        if not isinstance(obj, dict):
            return obj
        
        flattened = {}
        for key, value in obj.items():
            if isinstance(value, dict):
                # é€’å½’æ‰å¹³åŒ–åµŒå¥—å­—å…¸
                nested = self._flatten_all_dicts(value, separator)
                for nested_key, nested_value in nested.items():
                    flattened[f"{key}{separator}{nested_key}"] = nested_value
            elif isinstance(value, list):
                # åˆ—è¡¨åº”è¯¥å·²ç»åœ¨ä¹‹å‰è¢«å±•å¼€ï¼Œè¿™é‡Œä½œä¸ºå¤‡ç”¨å¤„ç†
                if len(value) > 0 and isinstance(value[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œæ‰å¹³åŒ–ç¬¬ä¸€ä¸ªå­—å…¸
                    first_dict = self._flatten_all_dicts(value[0], separator)
                    for nested_key, nested_value in first_dict.items():
                        flattened[f"{key}{separator}{nested_key}"] = nested_value
                else:
                    flattened[key] = str(value)
            else:
                flattened[key] = value
        
        return flattened
    
    def _analyze_tidy_data_quality(self, df):
        """åˆ†ææ•´æ´æ•°æ®è´¨é‡"""
        analysis = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'has_nested_columns': False,
            'has_list_data': False,
            'has_dict_data': False,
            'data_types': {},
            'tidy_score': 100  # æ»¡åˆ†100åˆ†
        }
        
        # æ£€æŸ¥åˆ—åæ˜¯å¦åŒ…å«åˆ†éš”ç¬¦ï¼ˆåµŒå¥—ç»“æ„ï¼‰
        nested_columns = [col for col in df.columns if '.' in col]
        if nested_columns:
            analysis['has_nested_columns'] = True
            analysis['tidy_score'] -= 20
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        for col in df.columns:
            sample_values = df[col].dropna().head(5)
            if len(sample_values) > 0:
                first_value = sample_values.iloc[0]
                data_type = type(first_value).__name__
                analysis['data_types'][col] = data_type
                
                if isinstance(first_value, list):
                    analysis['has_list_data'] = True
                    analysis['tidy_score'] -= 30
                elif isinstance(first_value, dict):
                    analysis['has_dict_data'] = True
                    analysis['tidy_score'] -= 30
        
        # ç¡®ä¿åˆ†æ•°ä¸ä¸ºè´Ÿæ•°
        analysis['tidy_score'] = max(0, analysis['tidy_score'])
        
        return analysis
    
    def analyze_json_structure(self, json_data: Union[str, List, Dict]) -> Dict[str, Any]:
        """åˆ†æJSONæ•°æ®ç»“æ„"""
        try:
            if isinstance(json_data, str):
                data = json.loads(json_data)
            else:
                data = json_data
            
            analysis = {
                'type': type(data).__name__,
                'size': len(data) if isinstance(data, (list, dict)) else 1,
                'has_lists': False,
                'has_nested_objects': False,
                'sample_keys': [],
                'complex_columns': [],
                'estimated_tidy_rows': 0
            }
            
            if isinstance(data, list) and len(data) > 0:
                sample_item = data[0]
                analysis['sample_keys'] = list(sample_item.keys()) if isinstance(sample_item, dict) else []
                
                # åˆ†æåµŒå¥—ç»“æ„
                list_count = 0
                dict_count = 0
                for key, value in sample_item.items() if isinstance(sample_item, dict) else []:
                    if isinstance(value, list):
                        analysis['has_lists'] = True
                        list_count += 1
                        analysis['complex_columns'].append({
                            'column': key,
                            'type': 'list',
                            'sample_length': len(value) if value else 0
                        })
                    elif isinstance(value, dict):
                        analysis['has_nested_objects'] = True
                        dict_count += 1
                        analysis['complex_columns'].append({
                            'column': key,
                            'type': 'dict',
                            'sample_keys': list(value.keys())[:5]
                        })
                
                # ä¼°ç®—æ•´æ´æ•°æ®è¡Œæ•°
                estimated_rows = len(data)
                for col_info in analysis['complex_columns']:
                    if col_info['type'] == 'list':
                        estimated_rows *= max(1, col_info['sample_length'])
                analysis['estimated_tidy_rows'] = estimated_rows
            
            return analysis
            
        except Exception as e:
            return {
                'error': str(e),
                'type': 'unknown'
            }
    
    def get_conversion_suggestions(self, analysis: Dict[str, Any]) -> List[str]:
        """æ ¹æ®ç»“æ„åˆ†ææä¾›è½¬æ¢å»ºè®®"""
        suggestions = []
        
        if analysis.get('has_lists'):
            suggestions.append("æ£€æµ‹åˆ°åˆ—è¡¨å­—æ®µï¼Œå°†å®Œå…¨å±•å¼€ä¸ºç¬›å¡å°”ç§¯ä»¥è·å¾—çœŸæ­£çš„æ•´æ´æ•°æ®")
        
        if analysis.get('has_nested_objects'):
            suggestions.append("æ£€æµ‹åˆ°åµŒå¥—å¯¹è±¡ï¼Œå°†å®Œå…¨æ‰å¹³åŒ–ä¸ºå•å±‚ç»“æ„")
        
        if analysis.get('estimated_tidy_rows', 0) > 1000:
            suggestions.append("é¢„è®¡è½¬æ¢åæ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†ä»¥æé«˜æ€§èƒ½")
        
        if not suggestions:
            suggestions.append("æ•°æ®ç»“æ„ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ•´æ´æ ¼å¼")
        
        return suggestions

def render_tidy_conversion_section():
    """æ¸²æŸ“æ•´æ´æ•°æ®è½¬æ¢éƒ¨åˆ†"""
    
    st.markdown("---")
    st.markdown('<h3 class="sub-header">ğŸ§¹ æ•´æ´æ•°æ®è½¬æ¢</h3>', unsafe_allow_html=True)
    
    # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹
    converter = TidyDataConverter()
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        padding: 20px;
        border-radius: 12px;
        color: white;
        margin-bottom: 20px;
        box-shadow: 0 4px 16px rgba(16, 185, 129, 0.2);
    ">
        <h4 style="color: white; margin-bottom: 15px; text-align: center;">ğŸ§¹ çœŸæ­£çš„æ•´æ´æ•°æ®è½¬æ¢å™¨</h4>
        <p style="font-size: 16px; line-height: 1.6; margin-bottom: 15px; text-align: center;">
            <strong>ğŸ’¡ å®Œå…¨ç¬¦åˆTidy DataåŸåˆ™çš„æ•°æ®è½¬æ¢</strong><br>
            å½»åº•å±•å¼€æ‰€æœ‰åˆ—è¡¨å­—æ®µï¼Œå®Œå…¨æ‰å¹³åŒ–åµŒå¥—ç»“æ„ï¼Œç”ŸæˆçœŸæ­£çš„æ•´æ´æ•°æ®æ ¼å¼ã€‚
        </p>
        <div style="display: flex; gap: 20px; margin-bottom: 15px;">
            <div style="flex: 1; background: rgba(255,255,255,0.15); padding: 15px; border-radius: 8px; backdrop-filter: blur(10px);">
                <h5 style="color: #FDE68A; margin-bottom: 10px;">ğŸ§¹ å®Œå…¨æ•´æ´</h5>
                <ul style="margin: 0; padding-left: 15px; font-size: 14px;">
                    <li>å±•å¼€æ‰€æœ‰åˆ—è¡¨å­—æ®µ</li>
                    <li>æ‰å¹³åŒ–æ‰€æœ‰åµŒå¥—</li>
                    <li>ç¬¦åˆTidy DataåŸåˆ™</li>
                    <li>é€‚åˆæ•°æ®åˆ†æ</li>
                </ul>
            </div>
            <div style="flex: 1; background: rgba(255,255,255,0.15); padding: 15px; border-radius: 8px; backdrop-filter: blur(10px);">
                <h5 style="color: #A7F3D0; margin-bottom: 10px;">ğŸ“Š æ•°æ®è´¨é‡</h5>
                <ul style="margin: 0; padding-left: 15px; font-size: 14px;">
                    <li>è´¨é‡è¯„åˆ†ç³»ç»Ÿ</li>
                    <li>è½¬æ¢æ•ˆæœåˆ†æ</li>
                    <li>æ•°æ®å®Œæ•´æ€§ä¿è¯</li>
                    <li>å¤šæ ¼å¼è¾“å‡º</li>
                </ul>
            </div>
        </div>
        <p style="font-size: 14px; margin: 0; text-align: center; opacity: 0.9;">
            <strong>ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š</strong> æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ ã€ç»Ÿè®¡å»ºæ¨¡ã€æ•°æ®å¯è§†åŒ–
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ğŸ“ ä¸Šä¼ JSONæ–‡ä»¶",
        type=converter.supported_input_formats,
        help="æ”¯æŒJSONæ ¼å¼æ–‡ä»¶ï¼Œå°†è½¬æ¢ä¸ºçœŸæ­£çš„æ•´æ´æ•°æ®æ ¼å¼"
    )
    
    if uploaded_file is not None:
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_content = uploaded_file.read().decode("utf-8")
            
            # åˆ†ææ•°æ®ç»“æ„
            analysis = converter.analyze_json_structure(file_content)
            
            if 'error' not in analysis:
                st.success(f"âœ… æ–‡ä»¶è§£ææˆåŠŸï¼æ•°æ®ç±»å‹: {analysis['type']}, å¤§å°: {analysis['size']}")
                
                # æ˜¾ç¤ºæ•°æ®ç»“æ„ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ•°æ®ç±»å‹", analysis['type'])
                with col2:
                    st.metric("åŸå§‹è®°å½•æ•°", analysis['size'])
                with col3:
                    st.metric("é¢„è®¡æ•´æ´è¡Œæ•°", analysis['estimated_tidy_rows'])
                with col4:
                    st.metric("å¤æ‚å­—æ®µæ•°", len(analysis['complex_columns']))
                
                # æ˜¾ç¤ºå¤æ‚å­—æ®µä¿¡æ¯
                if analysis['complex_columns']:
                    st.write("**ğŸ” å¤æ‚å­—æ®µåˆ†æï¼š**")
                    for col_info in analysis['complex_columns']:
                        if col_info['type'] == 'list':
                            st.write(f"â€¢ {col_info['column']}: åˆ—è¡¨ç±»å‹ (ç¤ºä¾‹é•¿åº¦: {col_info['sample_length']})")
                        elif col_info['type'] == 'dict':
                            st.write(f"â€¢ {col_info['column']}: å­—å…¸ç±»å‹ (åŒ…å«é”®: {', '.join(col_info['sample_keys'][:5])}{'...' if len(col_info['sample_keys']) > 5 else ''})")
                
                # è½¬æ¢é€‰é¡¹
                st.markdown("---")
                st.subheader("âš™ï¸ è½¬æ¢é…ç½®")
                
                col1, col2 = st.columns(2)
                with col1:
                    separator = st.text_input(
                        "åµŒå¥—å­—æ®µåˆ†éš”ç¬¦", 
                        value=".",
                        help="ç”¨äºå±•å¼€åµŒå¥—å­—æ®µï¼Œå¦‚ info.age"
                    )
                    fill_na = st.text_input(
                        "ç¼ºå¤±å€¼å¡«å……", 
                        value="",
                        help="ç”¨äºå¡«å……è½¬æ¢åçš„ç¼ºå¤±å€¼"
                    )
                
                with col2:
                    encoding = st.selectbox(
                        "æ–‡ä»¶ç¼–ç ",
                        ["utf-8-sig", "utf-8", "gbk", "gb2312"],
                        help="é€‰æ‹©è¾“å‡ºæ–‡ä»¶çš„ç¼–ç æ ¼å¼ï¼Œæ¨èä½¿ç”¨utf-8-sigä»¥æ”¯æŒä¸­æ–‡"
                    )
                    max_preview = st.number_input(
                        "é¢„è§ˆè¡Œæ•°", 
                        min_value=5, 
                        max_value=50, 
                        value=10,
                        help="è½¬æ¢ç»“æœé¢„è§ˆçš„è¡Œæ•°"
                    )
                
                # æ‰§è¡Œè½¬æ¢
                if st.button("ğŸ§¹ æ‰§è¡Œæ•´æ´è½¬æ¢", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨è½¬æ¢ä¸ºæ•´æ´æ•°æ®..."):
                        result = converter.convert_to_tidy_data(
                            json_data=file_content,
                            separator=separator,
                            fill_na=fill_na,
                            max_preview_rows=max_preview,
                            encoding=encoding
                        )
                        
                        if result['success']:
                            st.success("âœ… æ•´æ´æ•°æ®è½¬æ¢å®Œæˆï¼")
                            
                            # æ˜¾ç¤ºè½¬æ¢ä¿¡æ¯
                            col1, col2 = st.columns(2)
                            with col1:
                                st.info(result['info_message'])
                            with col2:
                                st.info(result['explode_message'])
                            
                            # æ˜¾ç¤ºæ•´æ´æ•°æ®è´¨é‡è¯„åˆ†
                            tidy_analysis = result['tidy_analysis']
                            st.subheader("ğŸ“Š æ•´æ´æ•°æ®è´¨é‡è¯„åˆ†")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("æ•´æ´åº¦è¯„åˆ†", f"{tidy_analysis['tidy_score']}/100")
                            with col2:
                                st.metric("è½¬æ¢åè¡Œæ•°", tidy_analysis['total_rows'])
                            with col3:
                                st.metric("è½¬æ¢ååˆ—æ•°", tidy_analysis['total_columns'])
                            with col4:
                                st.metric("æ•°æ®ç±»å‹æ•°", len(set(tidy_analysis['data_types'].values())))
                            
                            # è´¨é‡è¯„ä¼°
                            if tidy_analysis['tidy_score'] >= 90:
                                st.success("ğŸ‰ ä¼˜ç§€ï¼æ•°æ®å®Œå…¨ç¬¦åˆæ•´æ´æ•°æ®åŸåˆ™")
                            elif tidy_analysis['tidy_score'] >= 70:
                                st.warning("âš ï¸ è‰¯å¥½ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
                            else:
                                st.error("âŒ éœ€è¦è¿›ä¸€æ­¥å¤„ç†ä»¥è¾¾åˆ°æ•´æ´æ•°æ®æ ‡å‡†")
                            
                            # æ˜¾ç¤ºè½¬æ¢ç»“æœé¢„è§ˆ
                            st.subheader("ğŸ“‹ æ•´æ´æ•°æ®é¢„è§ˆ")
                            st.dataframe(result['preview_data'], use_container_width=True)
                            
                            # æ•°æ®ç±»å‹ä¿¡æ¯
                            st.subheader("ğŸ“ˆ æ•°æ®ç±»å‹åˆ†æ")
                            dtype_df = pd.DataFrame([
                                {'åˆ—å': col, 'æ•°æ®ç±»å‹': str(dtype)} 
                                for col, dtype in result['dtypes'].items()
                            ])
                            st.dataframe(dtype_df, use_container_width=True)
                            
                            # ä¸‹è½½è½¬æ¢ç»“æœ
                            st.subheader("ğŸ“¥ ä¸‹è½½æ•´æ´æ•°æ®")
                            
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                # CSVä¸‹è½½
                                st.download_button(
                                    label="ğŸ“„ ä¸‹è½½CSVæ–‡ä»¶",
                                    data=result['csv_data'],
                                    file_name=f"tidy_data_{uploaded_file.name.replace('.json', '.csv')}",
                                    mime="text/csv",
                                    use_container_width=True
                                )
                            
                            with col2:
                                # Excelä¸‹è½½
                                excel_buffer = io.BytesIO()
                                result['dataframe'].to_excel(excel_buffer, index=False, engine='openpyxl')
                                excel_data = excel_buffer.getvalue()
                                st.download_button(
                                    label="ğŸ“Š ä¸‹è½½Excelæ–‡ä»¶",
                                    data=excel_data,
                                    file_name=f"tidy_data_{uploaded_file.name.replace('.json', '.xlsx')}",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
                            
                            with col3:
                                # JSONä¸‹è½½
                                json_data = result['dataframe'].to_json(orient='records', indent=2, force_ascii=False)
                                st.download_button(
                                    label="ğŸ“‹ ä¸‹è½½JSONæ–‡ä»¶",
                                    data=json_data,
                                    file_name=f"tidy_data_{uploaded_file.name.replace('.json', '_tidy.json')}",
                                    mime="application/json",
                                    use_container_width=True
                                )
                            
                            # ä¿å­˜è½¬æ¢åçš„æ•°æ®åˆ°session state
                            st.session_state.tidy_data = result['dataframe']
                            st.success("âœ… æ•´æ´æ•°æ®å·²ä¿å­˜ï¼Œå¯åœ¨å…¶ä»–é¡µé¢ä½¿ç”¨")
                            
                        else:
                            st.error(f"âŒ è½¬æ¢å¤±è´¥ï¼š{result['error']}")
            else:
                st.error(f"âŒ æ–‡ä»¶è§£æå¤±è´¥ï¼š{analysis['error']}")
                
        except Exception as e:
            st.error(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
    else:
        st.info("ğŸ“ è¯·ä¸Šä¼ JSONæ–‡ä»¶ä»¥å¼€å§‹æ•´æ´æ•°æ®è½¬æ¢")
        
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.markdown("---")
        st.subheader("ğŸ“– æ•´æ´æ•°æ®åŸåˆ™")
        
        st.markdown("""
        **Tidy Data ä¸‰åŸåˆ™ï¼š**
        1. **æ¯ä¸ªå˜é‡å ä¸€åˆ—** - æ¯ä¸ªæµ‹é‡å˜é‡éƒ½æœ‰è‡ªå·±çš„åˆ—
        2. **æ¯ä¸ªè§‚æµ‹å ä¸€è¡Œ** - æ¯ä¸ªè§‚æµ‹å•å…ƒéƒ½æœ‰è‡ªå·±çš„è¡Œ
        3. **æ¯ä¸ªå€¼å ä¸€ä¸ªå•å…ƒæ ¼** - æ¯ä¸ªå€¼éƒ½åœ¨è‡ªå·±çš„å•å…ƒæ ¼ä¸­
        
        **è½¬æ¢ç‰¹æ€§ï¼š**
        - å®Œå…¨å±•å¼€æ‰€æœ‰åˆ—è¡¨å­—æ®µï¼ˆç¬›å¡å°”ç§¯ï¼‰
        - å®Œå…¨æ‰å¹³åŒ–æ‰€æœ‰åµŒå¥—å­—å…¸
        - ç”ŸæˆçœŸæ­£çš„æ•´æ´æ•°æ®æ ¼å¼
        - é€‚åˆæ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ 
        
        **è¾“å‡ºæ ¼å¼ï¼š**
        - CSVï¼šæ ‡å‡†é€—å·åˆ†éš”å€¼æ ¼å¼
        - Excelï¼šåŠŸèƒ½ä¸°å¯Œçš„è¡¨æ ¼æ ¼å¼
        - JSONï¼šé‡æ–°æ ¼å¼åŒ–çš„JSONæ•°æ®
        """)
        
        # æ˜¾ç¤ºç¤ºä¾‹
        st.markdown("---")
        st.subheader("ğŸ“ è½¬æ¢ç¤ºä¾‹")
        
        example_data = [
            {
                "id": 1,
                "name": "å¼ ä¸‰",
                "skills": ["Python", "SQL"],
                "projects": [
                    {"name": "é¡¹ç›®A", "role": "å¼€å‘"},
                    {"name": "é¡¹ç›®B", "role": "æµ‹è¯•"}
                ]
            }
        ]
        
        st.json(example_data)
        st.caption("è½¬æ¢åï¼šæ¯ä¸ªæŠ€èƒ½å’Œé¡¹ç›®çš„ç»„åˆéƒ½ä¼šç”Ÿæˆä¸€è¡Œæ•°æ®")
